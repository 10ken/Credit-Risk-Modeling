{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ea7d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b52a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32581 rows and 12 features.\n",
      "person_age                      int64\n",
      "person_income                   int64\n",
      "person_home_ownership          object\n",
      "person_emp_length             float64\n",
      "loan_intent                    object\n",
      "loan_grade                     object\n",
      "loan_amnt                       int64\n",
      "loan_int_rate                 float64\n",
      "loan_status                     int64\n",
      "loan_percent_income           float64\n",
      "cb_person_default_on_file      object\n",
      "cb_person_cred_hist_length      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennethleung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/kennethleung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/kennethleung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/kennethleung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/kennethleung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/kennethleung/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      8195\n",
      "           1       0.63      0.53      0.58      2230\n",
      "\n",
      "    accuracy                           0.83     10425\n",
      "   macro avg       0.76      0.72      0.74     10425\n",
      "weighted avg       0.83      0.83      0.83     10425\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_xgb_model() got an unexpected keyword argument 'threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wj/gwqv8kfj18317lgnlmf6zypw0000gn/T/ipykernel_18783/1338753832.py\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mcredit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_for_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mcredit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_xgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mcredit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_xgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.36\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Default threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mcredit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_xgb_model() got an unexpected keyword argument 'threshold'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "class CreditRiskModel:\n",
    "    def __init__(self, data_path, n_components=14):\n",
    "        self.data_path = data_path\n",
    "        self.data = None\n",
    "        self.cleaned_data = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.y_pred_thres = None\n",
    "        self.log_preds = None\n",
    "        self.scaler = MinMaxScaler(feature_range=[0, 1])\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        self.log_model = LogisticRegression()\n",
    "        self.xgb_model = xgb.XGBClassifier()\n",
    "    \n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.data_path)\n",
    "        print(f\"There are {self.data.shape[0]} rows and {self.data.shape[1]} features.\")\n",
    "        print(self.data.dtypes)\n",
    "        return self.data\n",
    "    \n",
    "    def clean_data(self):\n",
    "        self.data = self.data.rename(\n",
    "            columns={\"cb_person_default_on_file\": \"default_hist\",\n",
    "                     \"cb_person_cred_hist_length\": \"cr_hist_len\"})\n",
    "        \n",
    "        # Handle missing values\n",
    "        self.data['person_emp_length'].fillna(self.data['person_emp_length'].median(), inplace=True)\n",
    "        self.data['loan_int_rate'].fillna(self.data['loan_int_rate'].median(), inplace=True)\n",
    "        \n",
    "        # Remove outliers\n",
    "        self.cleaned_data = self.data[self.data['person_age'] <= 100]\n",
    "\n",
    "        # One-hot encode categorical variables\n",
    "        num_col = self.cleaned_data.select_dtypes(exclude='object')\n",
    "        char_col = self.cleaned_data.select_dtypes(include='object')\n",
    "        encoded_char_col = pd.get_dummies(char_col)\n",
    "        self.cleaned_data = pd.concat([num_col, encoded_char_col], axis=1)\n",
    "        \n",
    "        return self.cleaned_data\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        Y = self.cleaned_data['loan_status']\n",
    "        X = self.cleaned_data.drop(columns=['loan_status'])\n",
    "        \n",
    "        # Scale features\n",
    "        data_rescaled = self.scaler.fit_transform(X)\n",
    "\n",
    "        # Apply PCA\n",
    "        pca_dataset = self.pca.fit_transform(data_rescaled)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(pca_dataset, Y, random_state=2020, test_size=0.32)\n",
    "    \n",
    "    def train_log_model(self):\n",
    "        self.log_model.fit(self.X_train, np.ravel(self.y_train))\n",
    "        y_pred_proba = self.log_model.predict_proba(self.X_test)[:, 1]\n",
    "        pca_predict_log = pd.DataFrame(y_pred_proba, columns=['prob_default'])\n",
    "        self.y_pred_thres = pca_predict_log['prob_default'].apply(lambda x: 1 if x > 0.36 else 0)\n",
    "        self.log_preds = pd.DataFrame(self.y_pred_thres, columns=['log_preds'])\n",
    "        print(classification_report(self.y_test, self.y_pred_thres))\n",
    "    \n",
    "    def preprocess_for_xgb(self):\n",
    "        Y = self.cleaned_data['loan_status']\n",
    "        X = self.cleaned_data.drop(columns=['loan_status'])\n",
    "        \n",
    "        # Add log_preds as a feature and convert to numerical type\n",
    "        log_preds_numerical = self.log_preds.astype(int)  # Ensure log_preds is numerical\n",
    "        X = pd.concat([X.reset_index(drop=True), log_preds_numerical.reset_index(drop=True)], axis=1)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, Y, random_state=2020, test_size=0.30)\n",
    "    \n",
    "    def train_xgb_model(self):\n",
    "        self.xgb_model.fit(self.X_train, np.ravel(self.y_train))\n",
    "    \n",
    "    def evaluate_xgb_model(self, log_threshold=0.36):\n",
    "        predict_xgb = self.xgb_model.predict_proba(self.X_test)[:, 1]\n",
    "        predict_xgb_prob = pd.DataFrame(predict_xgb, columns=['Default Probability'])\n",
    "        y_pred_thres = predict_xgb_prob['Default Probability'].apply(lambda x: 1 if x > log_threshold else 0)\n",
    "        print(classification_report(self.y_test, y_pred_thres))\n",
    "    \n",
    "    def visualize_data(self):\n",
    "        plt.hist(self.data['person_emp_length'])\n",
    "        plt.xlabel(\"Employment Length\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(\"Freq vs Employment Length\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(self.data['loan_int_rate'])\n",
    "        plt.xlabel(\"Interest Rate\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(\"Freq vs Interest Rate\")\n",
    "        plt.show()\n",
    "\n",
    "        colors = [\"blue\", \"red\"]\n",
    "        plt.scatter(self.data['person_age'], self.data['loan_int_rate'],\n",
    "                    c=self.data['loan_status'],\n",
    "                    cmap=plt.cm.coolwarm, alpha=0.5)\n",
    "        plt.xlabel(\"Person Age\")\n",
    "        plt.ylabel(\"Loan Interest Rate\")\n",
    "        plt.title(\"Interest Rate vs Age\")\n",
    "        plt.show()\n",
    "\n",
    "# Workflow\n",
    "credit_model = CreditRiskModel('credit_risk_dataset.csv')\n",
    "credit_model.load_data()\n",
    "credit_model.clean_data()\n",
    "credit_model.preprocess_data()\n",
    "credit_model.train_log_model()\n",
    "credit_model.preprocess_for_xgb()\n",
    "credit_model.train_xgb_model()\n",
    "credit_model.evaluate_xgb_model(log_threshold=0.36)  # Default threshold\n",
    "credit_model.visualize_data()\n",
    "\n",
    "# Access the final predictions for further use\n",
    "final_predictions = credit_model.y_pred_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf251274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      7684\n",
      "           1       0.79      0.79      0.79      2089\n",
      "\n",
      "    accuracy                           0.91      9773\n",
      "   macro avg       0.87      0.87      0.87      9773\n",
      "weighted avg       0.91      0.91      0.91      9773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#0.25\n",
    "credit_model.evaluate_xgb_model(log_threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb495ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      7684\n",
      "           1       0.74      0.82      0.78      2089\n",
      "\n",
      "    accuracy                           0.90      9773\n",
      "   macro avg       0.84      0.87      0.86      9773\n",
      "weighted avg       0.90      0.90      0.90      9773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#0.20\n",
    "credit_model.evaluate_xgb_model(log_threshold=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd845f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      7684\n",
      "           1       0.66      0.86      0.75      2089\n",
      "\n",
      "    accuracy                           0.88      9773\n",
      "   macro avg       0.81      0.87      0.83      9773\n",
      "weighted avg       0.89      0.88      0.88      9773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#0.15\n",
    "credit_model.evaluate_xgb_model(log_threshold=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6db66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      7684\n",
      "           1       0.60      0.88      0.71      2089\n",
      "\n",
      "    accuracy                           0.85      9773\n",
      "   macro avg       0.78      0.86      0.81      9773\n",
      "weighted avg       0.89      0.85      0.86      9773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#0.12\n",
    "credit_model.evaluate_xgb_model(log_threshold=0.12)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29051232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
